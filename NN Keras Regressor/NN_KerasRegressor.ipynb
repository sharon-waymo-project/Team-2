{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is (17654, 15)\n",
      "Shape of the validation data is (6947, 15)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('/home/scg2151/waymo-project/csv_data/training/training_data_1_12.csv', names=[\"vx\", \"vy\", \"vz\", \"dx\", \"dy\", \"vfx\", \"vfy\", \"vfz\", \"afx\", \"afy\", \"afz\", \"num_v_labels\", \"ax\", \"ay\", \"az\"])\n",
    "test_dataset = pd.read_csv('/home/scg2151/waymo-project/csv_data/validation/validation_data_1_12.csv', names=[\"vx\", \"vy\", \"vz\", \"dx\", \"dy\", \"vfx\", \"vfy\", \"vfz\", \"afx\", \"afy\", \"afz\", \"num_v_labels\", \"ax\", \"ay\", \"az\"])\n",
    "train_dataset = train_dataset.drop(train_dataset.index[0])\n",
    "test_dataset = test_dataset.drop(test_dataset.index[0])\n",
    "print(\"Shape of the training data is\", train_dataset.shape)\n",
    "print(\"Shape of the validation data is\", test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X_train is (17654, 12)\n",
      "Shape of the X_test is (6947, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_dataset.iloc[:, :12]\n",
    "X_test = test_dataset.iloc[:, :12]\n",
    "print(\"Shape of the X_train is\", X_train.shape)\n",
    "print(\"Shape of the X_test is\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Y_train is (17654, 3)\n",
      "Shape of the Y_test is (6947, 3)\n"
     ]
    }
   ],
   "source": [
    "Y_train = train_dataset.iloc[:,12:]\n",
    "Y_test = test_dataset.iloc[:, 12:]\n",
    "print(\"Shape of the Y_train is\", Y_train.shape)\n",
    "print(\"Shape of the Y_test is\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=12, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "11769/11769 [==============================] - 1s 108us/step - loss: 0.1754\n",
      "Epoch 2/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.1518\n",
      "Epoch 3/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.1347\n",
      "Epoch 4/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.1215\n",
      "Epoch 5/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.1052\n",
      "Epoch 6/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0948\n",
      "Epoch 7/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0907\n",
      "Epoch 8/100\n",
      "11769/11769 [==============================] - 1s 86us/step - loss: 0.0879\n",
      "Epoch 9/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0856\n",
      "Epoch 10/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0839\n",
      "Epoch 11/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0824\n",
      "Epoch 12/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0808\n",
      "Epoch 13/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0797\n",
      "Epoch 14/100\n",
      "11769/11769 [==============================] - 1s 85us/step - loss: 0.0783\n",
      "Epoch 15/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0770\n",
      "Epoch 16/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0765\n",
      "Epoch 17/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0752\n",
      "Epoch 18/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0746\n",
      "Epoch 19/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0738\n",
      "Epoch 20/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0735\n",
      "Epoch 21/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0724\n",
      "Epoch 22/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0721\n",
      "Epoch 23/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0714\n",
      "Epoch 24/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0711\n",
      "Epoch 25/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0703\n",
      "Epoch 26/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0700\n",
      "Epoch 27/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0694\n",
      "Epoch 28/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0689\n",
      "Epoch 29/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0690\n",
      "Epoch 30/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0682\n",
      "Epoch 31/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0681\n",
      "Epoch 32/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0678\n",
      "Epoch 33/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0678\n",
      "Epoch 34/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0673\n",
      "Epoch 35/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0670\n",
      "Epoch 36/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0674\n",
      "Epoch 37/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0669\n",
      "Epoch 38/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0667\n",
      "Epoch 39/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0664\n",
      "Epoch 40/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0663\n",
      "Epoch 41/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0659\n",
      "Epoch 42/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0658\n",
      "Epoch 43/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0656\n",
      "Epoch 44/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0655\n",
      "Epoch 45/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0654\n",
      "Epoch 46/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0652\n",
      "Epoch 47/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0650\n",
      "Epoch 48/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0651\n",
      "Epoch 49/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0648\n",
      "Epoch 50/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0647\n",
      "Epoch 51/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0645\n",
      "Epoch 52/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0645\n",
      "Epoch 53/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0643\n",
      "Epoch 54/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0640\n",
      "Epoch 55/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0639\n",
      "Epoch 56/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0639\n",
      "Epoch 57/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0636\n",
      "Epoch 58/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0636\n",
      "Epoch 59/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0632\n",
      "Epoch 60/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0632\n",
      "Epoch 61/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0629\n",
      "Epoch 62/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0628\n",
      "Epoch 63/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0627\n",
      "Epoch 64/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0624\n",
      "Epoch 65/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0623\n",
      "Epoch 66/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0624\n",
      "Epoch 67/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0622\n",
      "Epoch 68/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0619\n",
      "Epoch 69/100\n",
      "11769/11769 [==============================] - 1s 78us/step - loss: 0.0622\n",
      "Epoch 70/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0615\n",
      "Epoch 71/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0614\n",
      "Epoch 72/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0615\n",
      "Epoch 73/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0614\n",
      "Epoch 74/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0611\n",
      "Epoch 75/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0612\n",
      "Epoch 76/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0610\n",
      "Epoch 77/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0609\n",
      "Epoch 78/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0607\n",
      "Epoch 79/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0606\n",
      "Epoch 80/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0604\n",
      "Epoch 81/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0596\n",
      "Epoch 82/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0590\n",
      "Epoch 83/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0584\n",
      "Epoch 84/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0578\n",
      "Epoch 85/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0568\n",
      "Epoch 86/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0564\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0560\n",
      "Epoch 88/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0557\n",
      "Epoch 89/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0555\n",
      "Epoch 90/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0553\n",
      "Epoch 91/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0551\n",
      "Epoch 92/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0549\n",
      "Epoch 93/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0547\n",
      "Epoch 94/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0544\n",
      "Epoch 95/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0543\n",
      "Epoch 96/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0542\n",
      "Epoch 97/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0543\n",
      "Epoch 98/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0545\n",
      "Epoch 99/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0539\n",
      "Epoch 100/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0540\n",
      "5885/5885 [==============================] - 0s 32us/step\n",
      "Epoch 1/100\n",
      "11769/11769 [==============================] - 1s 93us/step - loss: 0.1524\n",
      "Epoch 2/100\n",
      "11769/11769 [==============================] - 1s 86us/step - loss: 0.1325\n",
      "Epoch 3/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.1164\n",
      "Epoch 4/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.1044\n",
      "Epoch 5/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0982\n",
      "Epoch 6/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0944\n",
      "Epoch 7/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0922\n",
      "Epoch 8/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0903\n",
      "Epoch 9/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0888\n",
      "Epoch 10/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0866\n",
      "Epoch 11/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0849\n",
      "Epoch 12/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0829\n",
      "Epoch 13/100\n",
      "11769/11769 [==============================] - 1s 85us/step - loss: 0.0801\n",
      "Epoch 14/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0764\n",
      "Epoch 15/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0711\n",
      "Epoch 16/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0669\n",
      "Epoch 17/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0639\n",
      "Epoch 18/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0616\n",
      "Epoch 19/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0603\n",
      "Epoch 20/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0595\n",
      "Epoch 21/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0585\n",
      "Epoch 22/100\n",
      "11769/11769 [==============================] - 1s 85us/step - loss: 0.0574\n",
      "Epoch 23/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0567\n",
      "Epoch 24/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0562\n",
      "Epoch 25/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0555\n",
      "Epoch 26/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0552\n",
      "Epoch 27/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0546\n",
      "Epoch 28/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0543\n",
      "Epoch 29/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0536\n",
      "Epoch 30/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0536\n",
      "Epoch 31/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0533\n",
      "Epoch 32/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0527\n",
      "Epoch 33/100\n",
      "11769/11769 [==============================] - 1s 85us/step - loss: 0.0523\n",
      "Epoch 34/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0520\n",
      "Epoch 35/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0513\n",
      "Epoch 36/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0513\n",
      "Epoch 37/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0504\n",
      "Epoch 38/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0504\n",
      "Epoch 39/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0500\n",
      "Epoch 40/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0495\n",
      "Epoch 41/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0492\n",
      "Epoch 42/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0490\n",
      "Epoch 43/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0485\n",
      "Epoch 44/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0482\n",
      "Epoch 45/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0481\n",
      "Epoch 46/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0478\n",
      "Epoch 47/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0476\n",
      "Epoch 48/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0474\n",
      "Epoch 49/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0471\n",
      "Epoch 50/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0467\n",
      "Epoch 51/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0467\n",
      "Epoch 52/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0466\n",
      "Epoch 53/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0461\n",
      "Epoch 54/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0462\n",
      "Epoch 55/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0460\n",
      "Epoch 56/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0458\n",
      "Epoch 57/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0456\n",
      "Epoch 58/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0453\n",
      "Epoch 59/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0452\n",
      "Epoch 60/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0452\n",
      "Epoch 61/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0450\n",
      "Epoch 62/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0449\n",
      "Epoch 63/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0447\n",
      "Epoch 64/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0447\n",
      "Epoch 65/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0442\n",
      "Epoch 66/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0442\n",
      "Epoch 67/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0439\n",
      "Epoch 68/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0437\n",
      "Epoch 69/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0438\n",
      "Epoch 70/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0436\n",
      "Epoch 71/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0435\n",
      "Epoch 72/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0432\n",
      "Epoch 73/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0431\n",
      "Epoch 74/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0432\n",
      "Epoch 75/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0430\n",
      "Epoch 76/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0428\n",
      "Epoch 77/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0428\n",
      "Epoch 78/100\n",
      "11769/11769 [==============================] - 1s 86us/step - loss: 0.0426\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0427\n",
      "Epoch 80/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0426\n",
      "Epoch 81/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0425\n",
      "Epoch 82/100\n",
      "11769/11769 [==============================] - 1s 85us/step - loss: 0.0423\n",
      "Epoch 83/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0424\n",
      "Epoch 84/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0422\n",
      "Epoch 85/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0421\n",
      "Epoch 86/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0421\n",
      "Epoch 87/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0421\n",
      "Epoch 88/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0422\n",
      "Epoch 89/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0420\n",
      "Epoch 90/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0418\n",
      "Epoch 91/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0419\n",
      "Epoch 92/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0416\n",
      "Epoch 93/100\n",
      "11769/11769 [==============================] - 1s 83us/step - loss: 0.0418\n",
      "Epoch 94/100\n",
      "11769/11769 [==============================] - 1s 84us/step - loss: 0.0415\n",
      "Epoch 95/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0416\n",
      "Epoch 96/100\n",
      "11769/11769 [==============================] - 1s 79us/step - loss: 0.0416\n",
      "Epoch 97/100\n",
      "11769/11769 [==============================] - 1s 80us/step - loss: 0.0414\n",
      "Epoch 98/100\n",
      "11769/11769 [==============================] - 1s 82us/step - loss: 0.0412\n",
      "Epoch 99/100\n",
      "11769/11769 [==============================] - 1s 81us/step - loss: 0.0414\n",
      "Epoch 100/100\n",
      "11769/11769 [==============================] - 1s 87us/step - loss: 0.0411\n",
      "5885/5885 [==============================] - 0s 39us/step\n",
      "Epoch 1/100\n",
      "11770/11770 [==============================] - 1s 104us/step - loss: 0.1826\n",
      "Epoch 2/100\n",
      "11770/11770 [==============================] - 1s 89us/step - loss: 0.1618\n",
      "Epoch 3/100\n",
      "11770/11770 [==============================] - 1s 89us/step - loss: 0.1469\n",
      "Epoch 4/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.1317\n",
      "Epoch 5/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.1200\n",
      "Epoch 6/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.1151\n",
      "Epoch 7/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.1121\n",
      "Epoch 8/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.1095\n",
      "Epoch 9/100\n",
      "11770/11770 [==============================] - 1s 87us/step - loss: 0.1062\n",
      "Epoch 10/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.1023\n",
      "Epoch 11/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0968\n",
      "Epoch 12/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0904\n",
      "Epoch 13/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0853\n",
      "Epoch 14/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0824\n",
      "Epoch 15/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0803\n",
      "Epoch 16/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0787\n",
      "Epoch 17/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0769\n",
      "Epoch 18/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0755\n",
      "Epoch 19/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0739\n",
      "Epoch 20/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0725\n",
      "Epoch 21/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0714\n",
      "Epoch 22/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0706\n",
      "Epoch 23/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0693\n",
      "Epoch 24/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0683\n",
      "Epoch 25/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0674\n",
      "Epoch 26/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0668\n",
      "Epoch 27/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0662\n",
      "Epoch 28/100\n",
      "11770/11770 [==============================] - 1s 89us/step - loss: 0.0658\n",
      "Epoch 29/100\n",
      "11770/11770 [==============================] - 1s 89us/step - loss: 0.0649\n",
      "Epoch 30/100\n",
      "11770/11770 [==============================] - 1s 90us/step - loss: 0.0644\n",
      "Epoch 31/100\n",
      "11770/11770 [==============================] - 1s 89us/step - loss: 0.0635\n",
      "Epoch 32/100\n",
      "11770/11770 [==============================] - 1s 90us/step - loss: 0.0635\n",
      "Epoch 33/100\n",
      "11770/11770 [==============================] - 1s 88us/step - loss: 0.0630\n",
      "Epoch 34/100\n",
      "11770/11770 [==============================] - 1s 89us/step - loss: 0.0628\n",
      "Epoch 35/100\n",
      "11770/11770 [==============================] - 1s 92us/step - loss: 0.0624\n",
      "Epoch 36/100\n",
      "11770/11770 [==============================] - 1s 91us/step - loss: 0.0622\n",
      "Epoch 37/100\n",
      "11770/11770 [==============================] - 1s 90us/step - loss: 0.0615\n",
      "Epoch 38/100\n",
      "11770/11770 [==============================] - 1s 87us/step - loss: 0.0615\n",
      "Epoch 39/100\n",
      "11770/11770 [==============================] - 1s 81us/step - loss: 0.0611\n",
      "Epoch 40/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0608\n",
      "Epoch 41/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0604\n",
      "Epoch 42/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0604\n",
      "Epoch 43/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0603\n",
      "Epoch 44/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0599\n",
      "Epoch 45/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0598\n",
      "Epoch 46/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0593\n",
      "Epoch 47/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0597\n",
      "Epoch 48/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0591\n",
      "Epoch 49/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0589\n",
      "Epoch 50/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0588\n",
      "Epoch 51/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0585\n",
      "Epoch 52/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0582\n",
      "Epoch 53/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0579\n",
      "Epoch 54/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0579\n",
      "Epoch 55/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0577\n",
      "Epoch 56/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0574\n",
      "Epoch 57/100\n",
      "11770/11770 [==============================] - 1s 87us/step - loss: 0.0573\n",
      "Epoch 58/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0572\n",
      "Epoch 59/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0569\n",
      "Epoch 60/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0564\n",
      "Epoch 61/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0564\n",
      "Epoch 62/100\n",
      "11770/11770 [==============================] - 1s 87us/step - loss: 0.0560\n",
      "Epoch 63/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0564\n",
      "Epoch 64/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0556\n",
      "Epoch 65/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0555\n",
      "Epoch 66/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0554\n",
      "Epoch 67/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0556\n",
      "Epoch 68/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0549\n",
      "Epoch 69/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0552\n",
      "Epoch 70/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0550\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0550\n",
      "Epoch 72/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0546\n",
      "Epoch 73/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0546\n",
      "Epoch 74/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0547\n",
      "Epoch 75/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0543\n",
      "Epoch 76/100\n",
      "11770/11770 [==============================] - 1s 87us/step - loss: 0.0541\n",
      "Epoch 77/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0539\n",
      "Epoch 78/100\n",
      "11770/11770 [==============================] - 1s 88us/step - loss: 0.0542\n",
      "Epoch 79/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0539\n",
      "Epoch 80/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0541\n",
      "Epoch 81/100\n",
      "11770/11770 [==============================] - 1s 81us/step - loss: 0.0536\n",
      "Epoch 82/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0536\n",
      "Epoch 83/100\n",
      "11770/11770 [==============================] - 1s 82us/step - loss: 0.0537\n",
      "Epoch 84/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0531\n",
      "Epoch 85/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0537\n",
      "Epoch 86/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0535\n",
      "Epoch 87/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0531\n",
      "Epoch 88/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0531\n",
      "Epoch 89/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0531\n",
      "Epoch 90/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0527\n",
      "Epoch 91/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0529\n",
      "Epoch 92/100\n",
      "11770/11770 [==============================] - 1s 83us/step - loss: 0.0526\n",
      "Epoch 93/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0526\n",
      "Epoch 94/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0525\n",
      "Epoch 95/100\n",
      "11770/11770 [==============================] - 1s 84us/step - loss: 0.0526\n",
      "Epoch 96/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0522\n",
      "Epoch 97/100\n",
      "11770/11770 [==============================] - 1s 85us/step - loss: 0.0526\n",
      "Epoch 98/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0519\n",
      "Epoch 99/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0522\n",
      "Epoch 100/100\n",
      "11770/11770 [==============================] - 1s 86us/step - loss: 0.0522\n",
      "5884/5884 [==============================] - 0s 42us/step\n",
      "Wider: -0.19 (0.03) MSE\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import random\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "numpy.random.seed(7)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=32, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "results = cross_val_score(pipeline,X_train , Y_train, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17654/17654 [==============================] - 2s 94us/step - loss: 0.1637\n",
      "Epoch 2/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.1347\n",
      "Epoch 3/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.1227\n",
      "Epoch 4/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.1142\n",
      "Epoch 5/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.1114\n",
      "Epoch 6/100\n",
      "17654/17654 [==============================] - 2s 88us/step - loss: 0.1094\n",
      "Epoch 7/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.1081\n",
      "Epoch 8/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.1064\n",
      "Epoch 9/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.1055\n",
      "Epoch 10/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.1033\n",
      "Epoch 11/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0994\n",
      "Epoch 12/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0898\n",
      "Epoch 13/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0813\n",
      "Epoch 14/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0789\n",
      "Epoch 15/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0774\n",
      "Epoch 16/100\n",
      "17654/17654 [==============================] - 1s 81us/step - loss: 0.0760\n",
      "Epoch 17/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.0753\n",
      "Epoch 18/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0741\n",
      "Epoch 19/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0736\n",
      "Epoch 20/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0728\n",
      "Epoch 21/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.0725\n",
      "Epoch 22/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0722\n",
      "Epoch 23/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.0718\n",
      "Epoch 24/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.0714\n",
      "Epoch 25/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0709\n",
      "Epoch 26/100\n",
      "17654/17654 [==============================] - 2s 87us/step - loss: 0.0706\n",
      "Epoch 27/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.0703\n",
      "Epoch 28/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0699\n",
      "Epoch 29/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0695\n",
      "Epoch 30/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0694\n",
      "Epoch 31/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0689\n",
      "Epoch 32/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0687\n",
      "Epoch 33/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0685\n",
      "Epoch 34/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0686\n",
      "Epoch 35/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0682\n",
      "Epoch 36/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0678\n",
      "Epoch 37/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0675\n",
      "Epoch 38/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.0674\n",
      "Epoch 39/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0674\n",
      "Epoch 40/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0673\n",
      "Epoch 41/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0672\n",
      "Epoch 42/100\n",
      "17654/17654 [==============================] - 1s 81us/step - loss: 0.0670\n",
      "Epoch 43/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0671\n",
      "Epoch 44/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0667\n",
      "Epoch 45/100\n",
      "17654/17654 [==============================] - 1s 81us/step - loss: 0.0667\n",
      "Epoch 46/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0667\n",
      "Epoch 47/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0667\n",
      "Epoch 48/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0663\n",
      "Epoch 49/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0663\n",
      "Epoch 50/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0661\n",
      "Epoch 51/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0659\n",
      "Epoch 52/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0658\n",
      "Epoch 53/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0659\n",
      "Epoch 54/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0657\n",
      "Epoch 55/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.0656\n",
      "Epoch 56/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0654\n",
      "Epoch 57/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0654\n",
      "Epoch 58/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0652\n",
      "Epoch 59/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0651\n",
      "Epoch 60/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0649\n",
      "Epoch 61/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0650\n",
      "Epoch 62/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0648\n",
      "Epoch 63/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.0648\n",
      "Epoch 64/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0648\n",
      "Epoch 65/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0646\n",
      "Epoch 66/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0648\n",
      "Epoch 67/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.0645\n",
      "Epoch 68/100\n",
      "17654/17654 [==============================] - 1s 81us/step - loss: 0.0645\n",
      "Epoch 69/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0643\n",
      "Epoch 70/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.0641\n",
      "Epoch 71/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0643\n",
      "Epoch 72/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0639\n",
      "Epoch 73/100\n",
      "17654/17654 [==============================] - 1s 81us/step - loss: 0.0640\n",
      "Epoch 74/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0638\n",
      "Epoch 75/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0639\n",
      "Epoch 76/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0639\n",
      "Epoch 77/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0637\n",
      "Epoch 78/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0634\n",
      "Epoch 79/100\n",
      "17654/17654 [==============================] - 2s 87us/step - loss: 0.0636\n",
      "Epoch 80/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0635\n",
      "Epoch 81/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0633\n",
      "Epoch 82/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0633\n",
      "Epoch 83/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.0631\n",
      "Epoch 84/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0631\n",
      "Epoch 85/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0630\n",
      "Epoch 86/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0629\n",
      "Epoch 87/100\n",
      "17654/17654 [==============================] - 2s 87us/step - loss: 0.0630\n",
      "Epoch 88/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.0628\n",
      "Epoch 89/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0628\n",
      "Epoch 90/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.0626\n",
      "Epoch 91/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.0628\n",
      "Epoch 92/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0626\n",
      "Epoch 93/100\n",
      "17654/17654 [==============================] - 1s 82us/step - loss: 0.0625\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0626\n",
      "Epoch 95/100\n",
      "17654/17654 [==============================] - 2s 86us/step - loss: 0.0624\n",
      "Epoch 96/100\n",
      "17654/17654 [==============================] - 1s 85us/step - loss: 0.0624\n",
      "Epoch 97/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0622\n",
      "Epoch 98/100\n",
      "17654/17654 [==============================] - 1s 84us/step - loss: 0.0623\n",
      "Epoch 99/100\n",
      "17654/17654 [==============================] - 1s 83us/step - loss: 0.0622\n",
      "Epoch 100/100\n",
      "17654/17654 [==============================] - 2s 85us/step - loss: 0.0623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardize',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('mlp',\n",
       "                 <keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe27ed646d8>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6947/6947 [==============================] - 0s 34us/step\n",
      "Mean Absolute Error: 0.28175507765427144\n",
      "Mean Squared Error: 0.20896955095342395\n",
      "Root Mean Squared Error: 0.4571318747948167\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
