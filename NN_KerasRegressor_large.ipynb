{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is (154371, 15)\n",
      "Shape of the validation data is (29004, 15)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('../train_final.csv', names=[\"vx\", \"vy\", \"vz\", \"dx\", \"dy\", \"vfx\", \"vfy\", \"vfz\", \"afx\", \"afy\", \"afz\", \"num_v_labels\", \"ax\", \"ay\", \"az\"])\n",
    "test_dataset = pd.read_csv('../test.csv', names=[\"vx\", \"vy\", \"vz\", \"dx\", \"dy\", \"vfx\", \"vfy\", \"vfz\", \"afx\", \"afy\", \"afz\", \"num_v_labels\", \"ax\", \"ay\", \"az\"])\n",
    "train_dataset = train_dataset.drop(train_dataset.index[0])\n",
    "test_dataset = test_dataset.drop(test_dataset.index[0])\n",
    "print(\"Shape of the training data is\", train_dataset.shape)\n",
    "print(\"Shape of the validation data is\", test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X_train is (154371, 12)\n",
      "Shape of the X_test is (29004, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_dataset.iloc[:, :12]\n",
    "X_test = test_dataset.iloc[:, :12]\n",
    "print(\"Shape of the X_train is\", X_train.shape)\n",
    "print(\"Shape of the X_test is\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Y_train is (154371, 3)\n",
      "Shape of the Y_test is (29004, 3)\n"
     ]
    }
   ],
   "source": [
    "Y_train = train_dataset.iloc[:,12:]\n",
    "Y_test = test_dataset.iloc[:, 12:]\n",
    "print(\"Shape of the Y_train is\", Y_train.shape)\n",
    "print(\"Shape of the Y_test is\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=12, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "102914/102914 [==============================] - 13s 128us/step - loss: 0.2412\n",
      "Epoch 2/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1999\n",
      "Epoch 3/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1939\n",
      "Epoch 4/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1908\n",
      "Epoch 5/50\n",
      "102914/102914 [==============================] - 13s 124us/step - loss: 0.1891\n",
      "Epoch 6/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1879\n",
      "Epoch 7/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1870\n",
      "Epoch 8/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1865\n",
      "Epoch 9/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1859\n",
      "Epoch 10/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1854\n",
      "Epoch 11/50\n",
      "102914/102914 [==============================] - 13s 128us/step - loss: 0.1848\n",
      "Epoch 12/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1848\n",
      "Epoch 13/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1844\n",
      "Epoch 14/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1841\n",
      "Epoch 15/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1840\n",
      "Epoch 16/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1838\n",
      "Epoch 17/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1837\n",
      "Epoch 18/50\n",
      "102914/102914 [==============================] - 13s 127us/step - loss: 0.1834\n",
      "Epoch 19/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1833\n",
      "Epoch 20/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1830\n",
      "Epoch 21/50\n",
      "102914/102914 [==============================] - 13s 129us/step - loss: 0.1829\n",
      "Epoch 22/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1828\n",
      "Epoch 23/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1826\n",
      "Epoch 24/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1825\n",
      "Epoch 25/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1824\n",
      "Epoch 26/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1822\n",
      "Epoch 27/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1821\n",
      "Epoch 28/50\n",
      "102914/102914 [==============================] - 13s 124us/step - loss: 0.1821\n",
      "Epoch 29/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1820\n",
      "Epoch 30/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1819\n",
      "Epoch 31/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1818\n",
      "Epoch 32/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1817\n",
      "Epoch 33/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1816\n",
      "Epoch 34/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1816\n",
      "Epoch 35/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1814\n",
      "Epoch 36/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1813\n",
      "Epoch 37/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1812\n",
      "Epoch 38/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1811\n",
      "Epoch 39/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1810\n",
      "Epoch 40/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1809\n",
      "Epoch 41/50\n",
      "102914/102914 [==============================] - 13s 125us/step - loss: 0.1808\n",
      "Epoch 42/50\n",
      "102914/102914 [==============================] - 13s 128us/step - loss: 0.1808\n",
      "Epoch 43/50\n",
      "102914/102914 [==============================] - 13s 126us/step - loss: 0.1806\n",
      "Epoch 44/50\n",
      "102914/102914 [==============================] - 12s 117us/step - loss: 0.1805\n",
      "Epoch 45/50\n",
      "102914/102914 [==============================] - 11s 105us/step - loss: 0.1804\n",
      "Epoch 46/50\n",
      "102914/102914 [==============================] - 11s 105us/step - loss: 0.1804\n",
      "Epoch 47/50\n",
      "102914/102914 [==============================] - 10s 101us/step - loss: 0.1803\n",
      "Epoch 48/50\n",
      "102914/102914 [==============================] - 10s 101us/step - loss: 0.1802\n",
      "Epoch 49/50\n",
      "102914/102914 [==============================] - 10s 101us/step - loss: 0.1801\n",
      "Epoch 50/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1800\n",
      "51457/51457 [==============================] - 2s 37us/step\n",
      "Epoch 1/50\n",
      "102914/102914 [==============================] - 11s 102us/step - loss: 0.2619\n",
      "Epoch 2/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.2452\n",
      "Epoch 3/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.2354\n",
      "Epoch 4/50\n",
      "102914/102914 [==============================] - 10s 101us/step - loss: 0.2265\n",
      "Epoch 5/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.2073\n",
      "Epoch 6/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.2035\n",
      "Epoch 7/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.2022\n",
      "Epoch 8/50\n",
      "102914/102914 [==============================] - 11s 102us/step - loss: 0.2014\n",
      "Epoch 9/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.2003\n",
      "Epoch 10/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1994\n",
      "Epoch 11/50\n",
      "102914/102914 [==============================] - 10s 101us/step - loss: 0.1987\n",
      "Epoch 12/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1981\n",
      "Epoch 13/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1977\n",
      "Epoch 14/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1971\n",
      "Epoch 15/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1966\n",
      "Epoch 16/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1962\n",
      "Epoch 17/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1958\n",
      "Epoch 18/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1957\n",
      "Epoch 19/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1954\n",
      "Epoch 20/50\n",
      "102914/102914 [==============================] - 10s 102us/step - loss: 0.1951\n",
      "Epoch 21/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1950\n",
      "Epoch 22/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1948\n",
      "Epoch 23/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1947\n",
      "Epoch 24/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1946\n",
      "Epoch 25/50\n",
      "102914/102914 [==============================] - 11s 103us/step - loss: 0.1944\n",
      "Epoch 26/50\n",
      "102914/102914 [==============================] - 10s 101us/step - loss: 0.1943\n",
      "Epoch 27/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1941\n",
      "Epoch 28/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1937\n",
      "Epoch 29/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1936\n",
      "Epoch 30/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1934\n",
      "Epoch 31/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1932\n",
      "Epoch 32/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1930\n",
      "Epoch 33/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1926\n",
      "Epoch 34/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1925\n",
      "Epoch 35/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1922\n",
      "Epoch 36/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1920\n",
      "Epoch 37/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1919\n",
      "Epoch 38/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1916\n",
      "Epoch 39/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1914\n",
      "Epoch 40/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1913\n",
      "Epoch 41/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1912\n",
      "Epoch 42/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1910\n",
      "Epoch 43/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1908\n",
      "Epoch 44/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1906\n",
      "Epoch 45/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1905\n",
      "Epoch 46/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1903\n",
      "Epoch 47/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1903\n",
      "Epoch 48/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1901\n",
      "Epoch 49/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1899\n",
      "Epoch 50/50\n",
      "102914/102914 [==============================] - 11s 103us/step - loss: 0.1899\n",
      "51457/51457 [==============================] - 2s 38us/step\n",
      "Epoch 1/50\n",
      "102914/102914 [==============================] - 10s 101us/step - loss: 0.2446\n",
      "Epoch 2/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.2259\n",
      "Epoch 3/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.2144\n",
      "Epoch 4/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1937\n",
      "Epoch 5/50\n",
      "102914/102914 [==============================] - 11s 102us/step - loss: 0.1907\n",
      "Epoch 6/50\n",
      "102914/102914 [==============================] - 11s 102us/step - loss: 0.1891\n",
      "Epoch 7/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1881\n",
      "Epoch 8/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1873\n",
      "Epoch 9/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1867\n",
      "Epoch 10/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1861\n",
      "Epoch 11/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1857\n",
      "Epoch 12/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1853\n",
      "Epoch 13/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1847\n",
      "Epoch 14/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1840\n",
      "Epoch 15/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1837\n",
      "Epoch 16/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1834\n",
      "Epoch 17/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1830\n",
      "Epoch 18/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1826\n",
      "Epoch 19/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1823\n",
      "Epoch 20/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1821\n",
      "Epoch 21/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1817\n",
      "Epoch 22/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1817\n",
      "Epoch 23/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1814\n",
      "Epoch 24/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1814\n",
      "Epoch 25/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1810\n",
      "Epoch 26/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1809\n",
      "Epoch 27/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1806\n",
      "Epoch 28/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1804\n",
      "Epoch 29/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1803\n",
      "Epoch 30/50\n",
      "102914/102914 [==============================] - 11s 104us/step - loss: 0.1801\n",
      "Epoch 31/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1800\n",
      "Epoch 32/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1799\n",
      "Epoch 33/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1795\n",
      "Epoch 34/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1795\n",
      "Epoch 35/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1794\n",
      "Epoch 36/50\n",
      "102914/102914 [==============================] - 11s 107us/step - loss: 0.1792\n",
      "Epoch 37/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1789\n",
      "Epoch 38/50\n",
      "102914/102914 [==============================] - 10s 98us/step - loss: 0.1788\n",
      "Epoch 39/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1787\n",
      "Epoch 40/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1788\n",
      "Epoch 41/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1787\n",
      "Epoch 42/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1785\n",
      "Epoch 43/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1783\n",
      "Epoch 44/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1783\n",
      "Epoch 45/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1782\n",
      "Epoch 46/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1782\n",
      "Epoch 47/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1782\n",
      "Epoch 48/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1780\n",
      "Epoch 49/50\n",
      "102914/102914 [==============================] - 10s 100us/step - loss: 0.1779\n",
      "Epoch 50/50\n",
      "102914/102914 [==============================] - 10s 99us/step - loss: 0.1779\n",
      "51457/51457 [==============================] - 2s 38us/step\n",
      "Wider: -0.20 (0.01) MSE\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import random\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "numpy.random.seed(7)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=50, batch_size=32, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "results = cross_val_score(pipeline,X_train , Y_train, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "154371/154371 [==============================] - 16s 102us/step - loss: 0.2487\n",
      "Epoch 2/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.2201\n",
      "Epoch 3/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1984\n",
      "Epoch 4/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1963\n",
      "Epoch 5/50\n",
      "154371/154371 [==============================] - 16s 104us/step - loss: 0.1947\n",
      "Epoch 6/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1936\n",
      "Epoch 7/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1930\n",
      "Epoch 8/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1924\n",
      "Epoch 9/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1921\n",
      "Epoch 10/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1915\n",
      "Epoch 11/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1911\n",
      "Epoch 12/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1905\n",
      "Epoch 13/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1903\n",
      "Epoch 14/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1899\n",
      "Epoch 15/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1896\n",
      "Epoch 16/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1894\n",
      "Epoch 17/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1890\n",
      "Epoch 18/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1889\n",
      "Epoch 19/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1888\n",
      "Epoch 20/50\n",
      "154371/154371 [==============================] - 16s 101us/step - loss: 0.1885\n",
      "Epoch 21/50\n",
      "154371/154371 [==============================] - 15s 98us/step - loss: 0.1885\n",
      "Epoch 22/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1883\n",
      "Epoch 23/50\n",
      "154371/154371 [==============================] - 15s 98us/step - loss: 0.1880\n",
      "Epoch 24/50\n",
      "154371/154371 [==============================] - 15s 98us/step - loss: 0.1881\n",
      "Epoch 25/50\n",
      "154371/154371 [==============================] - 16s 102us/step - loss: 0.1879\n",
      "Epoch 26/50\n",
      "154371/154371 [==============================] - 15s 97us/step - loss: 0.1877\n",
      "Epoch 27/50\n",
      "154371/154371 [==============================] - 15s 97us/step - loss: 0.1876\n",
      "Epoch 28/50\n",
      "154371/154371 [==============================] - 15s 97us/step - loss: 0.1874\n",
      "Epoch 29/50\n",
      "154371/154371 [==============================] - 15s 98us/step - loss: 0.1874\n",
      "Epoch 30/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1872\n",
      "Epoch 31/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1873\n",
      "Epoch 32/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1870\n",
      "Epoch 33/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1870\n",
      "Epoch 34/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1869\n",
      "Epoch 35/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1870\n",
      "Epoch 36/50\n",
      "154371/154371 [==============================] - 15s 98us/step - loss: 0.1868\n",
      "Epoch 37/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1868\n",
      "Epoch 38/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1868\n",
      "Epoch 39/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1867\n",
      "Epoch 40/50\n",
      "154371/154371 [==============================] - 16s 101us/step - loss: 0.1867\n",
      "Epoch 41/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1866\n",
      "Epoch 42/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1867\n",
      "Epoch 43/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1866\n",
      "Epoch 44/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1866\n",
      "Epoch 45/50\n",
      "154371/154371 [==============================] - 16s 103us/step - loss: 0.1865\n",
      "Epoch 46/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1864\n",
      "Epoch 47/50\n",
      "154371/154371 [==============================] - 15s 98us/step - loss: 0.1864\n",
      "Epoch 48/50\n",
      "154371/154371 [==============================] - 15s 99us/step - loss: 0.1863\n",
      "Epoch 49/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1864\n",
      "Epoch 50/50\n",
      "154371/154371 [==============================] - 15s 100us/step - loss: 0.1863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardize',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('mlp',\n",
       "                 <keras.wrappers.scikit_learn.KerasRegressor object at 0x7f4fb4e2ca20>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6947/6947 [==============================] - 0s 34us/step\n",
      "Mean Absolute Error: 0.28175507765427144\n",
      "Mean Squared Error: 0.20896955095342395\n",
      "Root Mean Squared Error: 0.4571318747948167\n"
     ]
    }
   ],
   "source": [
    "# y_pred = pipeline.predict(X_test)\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))  \n",
    "# print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))  \n",
    "# print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29004/29004 [==============================] - 1s 33us/step\n",
      "Mean Absolute Error: 0.2783730108061561\n",
      "Mean Squared Error: 0.23353206525506384\n",
      "Root Mean Squared Error: 0.4832515548397789\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savetxt(\"val_pred_000_1495.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Y_test = Y_test.drop(Y_test.index[0])\n",
    "# Y_test.to_csv('val_000_truth.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>vfx</th>\n",
       "      <th>vfy</th>\n",
       "      <th>vfz</th>\n",
       "      <th>afx</th>\n",
       "      <th>afy</th>\n",
       "      <th>afz</th>\n",
       "      <th>num_v_labels</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.010605618475893</td>\n",
       "      <td>0.19745305845844996</td>\n",
       "      <td>0.0006035805949680477</td>\n",
       "      <td>7.836455717152788e-05</td>\n",
       "      <td>-2.6850703206580614e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.010692799278331</td>\n",
       "      <td>0.19743924029171467</td>\n",
       "      <td>0.0006035805949746076</td>\n",
       "      <td>7.836455729477147e-05</td>\n",
       "      <td>-2.6850703567047513e-07</td>\n",
       "      <td>6.526726234384042e-14</td>\n",
       "      <td>1.226211495973552e-12</td>\n",
       "      <td>-3.5864635868014113e-14</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.010727727658832</td>\n",
       "      <td>0.1975324912382348</td>\n",
       "      <td>0.0006035805949811678</td>\n",
       "      <td>7.83645574180148e-05</td>\n",
       "      <td>-2.6850703927513607e-07</td>\n",
       "      <td>6.527049852305224e-14</td>\n",
       "      <td>1.2262089339983428e-12</td>\n",
       "      <td>-3.586455580628882e-14</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.010792282517286</td>\n",
       "      <td>0.19756161448094645</td>\n",
       "      <td>0.0006035805949877278</td>\n",
       "      <td>7.83645575412584e-05</td>\n",
       "      <td>-2.6850704287980505e-07</td>\n",
       "      <td>6.526834107024436e-14</td>\n",
       "      <td>1.226211495973552e-12</td>\n",
       "      <td>-3.5864635868014113e-14</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.010937305172774</td>\n",
       "      <td>0.19752411707304418</td>\n",
       "      <td>0.000603580565301942</td>\n",
       "      <td>7.836481599479181e-05</td>\n",
       "      <td>-2.597143353837549e-07</td>\n",
       "      <td>-2.953585751987407e-10</td>\n",
       "      <td>2.5714821253364116e-09</td>\n",
       "      <td>8.748299882433754e-08</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vx   vy   vz                 dx                   dy  \\\n",
       "1  0.0  0.0  0.0  9.010605618475893  0.19745305845844996   \n",
       "2  0.0  0.0  0.0  9.010692799278331  0.19743924029171467   \n",
       "3  0.0  0.0  0.0  9.010727727658832   0.1975324912382348   \n",
       "4  0.0  0.0  0.0  9.010792282517286  0.19756161448094645   \n",
       "5  0.0  0.0  0.0  9.010937305172774  0.19752411707304418   \n",
       "\n",
       "                     vfx                    vfy                      vfz  \\\n",
       "1  0.0006035805949680477  7.836455717152788e-05  -2.6850703206580614e-07   \n",
       "2  0.0006035805949746076  7.836455729477147e-05  -2.6850703567047513e-07   \n",
       "3  0.0006035805949811678   7.83645574180148e-05  -2.6850703927513607e-07   \n",
       "4  0.0006035805949877278   7.83645575412584e-05  -2.6850704287980505e-07   \n",
       "5   0.000603580565301942  7.836481599479181e-05   -2.597143353837549e-07   \n",
       "\n",
       "                      afx                     afy                      afz  \\\n",
       "1                     0.0                     0.0                      0.0   \n",
       "2   6.526726234384042e-14   1.226211495973552e-12  -3.5864635868014113e-14   \n",
       "3   6.527049852305224e-14  1.2262089339983428e-12   -3.586455580628882e-14   \n",
       "4   6.526834107024436e-14   1.226211495973552e-12  -3.5864635868014113e-14   \n",
       "5  -2.953585751987407e-10  2.5714821253364116e-09    8.748299882433754e-08   \n",
       "\n",
       "  num_v_labels   ax   ay   az  \n",
       "1         29.0  0.0  0.0  0.0  \n",
       "2         28.0  0.0  0.0  0.0  \n",
       "3         29.0  0.0  0.0  0.0  \n",
       "4         29.0  0.0  0.0  0.0  \n",
       "5         29.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.to_csv('val_000_1495_truth.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "pkl.dump(pipeline, open('NN_Keras_Large.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
